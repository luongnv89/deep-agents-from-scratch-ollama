{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aabb159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"), override=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a407e4",
   "metadata": {},
   "source": [
    "## Context Offloading: Filesystem\n",
    "\n",
    "<img src=\"./assets/agent_header_files.png\" width=\"800\" style=\"display:block; margin-left:0;\">\n",
    "\n",
    "Agent context windows can grow rapidly during complex tasks—the average Manus task uses approximately 50 tool calls, creating substantial context accumulation. A powerful technique for managing this growth is **context offloading** through filesystem operations. Rather than storing all tool call observations and intermediate results directly in the context window, agents can strategically save information to files and [fetch it as-needed](https://blog.langchain.com/context-engineering-for-agents/), maintaining focus while preserving access to critical information.\n",
    "\n",
    "This approach has been successfully implemented by production systems like [Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus) and [Hugging Face Open Deep Research](https://huggingface.co/blog/open-deep-research). Anthropic's [multi-agent research system](https://www.anthropic.com/engineering/multi-agent-research-system#:~:text=Subagent%20output%20to%20a%20filesystem%20to%20minimize%20the%20%E2%80%98game%20of%20telephone.%E2%80%99) provides another compelling example, where subagents store their work in external systems and pass lightweight references back to coordinators. This prevents the \"game of telephone\" effect—information degradation as it passes through multiple agents—while enabling fresh subagents to spawn with clean contexts and retrieve stored context like research plans from memory when needed.\n",
    "\n",
    "By writing token-heavy context to files in sandboxed environments, agents can effectively manage memory while maintaining the ability to retrieve detailed information when necessary. This pattern is particularly valuable for structured outputs like code, reports, or data visualizations where specialized prompts produce better results than filtering through general coordinators, and for long-running research tasks where intermediate results need preservation without constant attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9854e27-f800-4563-9ed1-82837039cf97",
   "metadata": {},
   "source": [
    "### File Tools\n",
    "\n",
    "Our implementation uses a virtual filesystem approach that mocks the traditional filesystem within LangGraph state. The core insight is to use a simple dictionary where keys represent mock file paths and values contain the file content. This approach provides short-term, thread-wise persistence that's ideal for maintaining context within a single agent conversation, though it's not suited for information that needs to persist across different conversation threads. The file operations utilize LangGraph's `Command` type to update the agent state, enabling tools to modify the virtual filesystem and maintain proper state management throughout the agent's execution.\n",
    "\n",
    "You’ll build three file tools—`ls`, `read_file`, and `write_file`—that operate on the virtual file system.\n",
    "\n",
    "**Usage:** \n",
    "- When the LLM has information in its context that it wants to persist, it writes it to a file with `write_file`; later, the same agent or a subagent can retrieve it with `read_file`.\n",
    "- A tool call can write data to a file and provide the filename in the tool call return message to the LLM. The LLM can later decide to read some or all of the content, or could apply another tool to process the data. \n",
    "- Use `ls` to list available files.\n",
    "\n",
    "The read/write tools expect newline-delimited plain text (parsed with `str.splitlines()`).\n",
    "\n",
    "\n",
    "The descriptions in the prompts below describe in detail how they operate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe282a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  List all files in the virtual filesystem stored in agent state.                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and maintain awareness of your file organization.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  No parameters required - simply call ls() to see all available files.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  List all files in the virtual filesystem stored in agent state.                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and maintain awareness of your file organization.                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  No parameters required - simply call ls() to see all available files.                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import show_prompt\n",
    "\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    LS_DESCRIPTION,\n",
    "    READ_FILE_DESCRIPTION,\n",
    "    WRITE_FILE_DESCRIPTION,\n",
    ")\n",
    "\n",
    "show_prompt(LS_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc7bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Read content from a file in the virtual filesystem with optional pagination.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  to avoid context overflow.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Parameters:                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - file_path (required): Path to the file you want to read                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - offset (optional, default=0): Line number to start reading from                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - limit (optional, default=2000): Maximum number of lines to read                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Essential before making any edits to understand existing content. Always read a file before editing it.        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Read content from a file in the virtual filesystem with optional pagination.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  to avoid context overflow.                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Parameters:                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - file_path (required): Path to the file you want to read                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - offset (optional, default=0): Line number to start reading from                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - limit (optional, default=2000): Maximum number of lines to read                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Essential before making any edits to understand existing content. Always read a file before editing it.        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prompt(READ_FILE_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de27788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Create a new file or completely overwrite an existing file in the virtual filesystem.                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  rewrites. Files are stored persistently in agent state.                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Parameters:                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - file_path (required): Path where the file should be created/overwritten                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - content (required): The complete content to write to the file                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Important: This replaces the entire file content.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Create a new file or completely overwrite an existing file in the virtual filesystem.                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  rewrites. Files are stored persistently in agent state.                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Parameters:                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - file_path (required): Path where the file should be created/overwritten                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - content (required): The complete content to write to the file                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Important: This replaces the entire file content.                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prompt(WRITE_FILE_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d581826",
   "metadata": {},
   "source": [
    "Let's implement these functions below. There are two items worth noting. The first is the use of `@tool(description=PROMPT)`. Note that when `description=\"xyz\" is in the tool decorator, \"xyz\" is sent to the LLM and the docstring is suppressed. It is often more convenient to have lengthy descriptions in a separate prompts file. This provides space to explain both the operation of the tool and how it should be used in this application. The second item is the error messages. These messages are intended for the LLM vs a human user. In an agentic system, the LLM can use the information in error messages to retry the operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7f3968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/deep_agents_from_scratch/file_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/deep_agents_from_scratch/file_tools.py\n",
    "\"\"\"Virtual file system tools for agent state management.\n",
    "\n",
    "This module provides tools for managing a virtual filesystem stored in agent state,\n",
    "enabling context offloading and information persistence across agent interactions.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.types import Command\n",
    "\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    LS_DESCRIPTION,\n",
    "    READ_FILE_DESCRIPTION,\n",
    "    WRITE_FILE_DESCRIPTION,\n",
    ")\n",
    "from deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "\n",
    "@tool(description=LS_DESCRIPTION)\n",
    "def ls(state: Annotated[DeepAgentState, InjectedState]) -> list[str]:\n",
    "    \"\"\"List all files in the virtual filesystem.\"\"\"\n",
    "    return list(state.get(\"files\", {}).keys())\n",
    "\n",
    "\n",
    "@tool(description=READ_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def read_file(\n",
    "    file_path: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    offset: int = 0,\n",
    "    limit: int = 2000,\n",
    ") -> str:\n",
    "    \"\"\"Read file content from virtual filesystem with optional offset and limit.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the file to read\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        offset: Line number to start reading from (default: 0)\n",
    "        limit: Maximum number of lines to read (default: 2000)\n",
    "\n",
    "    Returns:\n",
    "        Formatted file content with line numbers, or error message if file not found\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    if file_path not in files:\n",
    "        return f\"Error: File '{file_path}' not found\"\n",
    "\n",
    "    content = files[file_path]\n",
    "    if not content:\n",
    "        return \"System reminder: File exists but has empty contents\"\n",
    "\n",
    "    lines = content.splitlines()\n",
    "    start_idx = offset\n",
    "    end_idx = min(start_idx + limit, len(lines))\n",
    "\n",
    "    if start_idx >= len(lines):\n",
    "        return f\"Error: Line offset {offset} exceeds file length ({len(lines)} lines)\"\n",
    "\n",
    "    result_lines = []\n",
    "    for i in range(start_idx, end_idx):\n",
    "        line_content = lines[i][:2000]  # Truncate long lines\n",
    "        result_lines.append(f\"{i + 1:6d}\\t{line_content}\")\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "\n",
    "@tool(description=WRITE_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def write_file(\n",
    "    file_path: str,\n",
    "    content: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> Command:\n",
    "    \"\"\"Write content to a file in the virtual filesystem.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path where the file should be created/updated\n",
    "        content: Content to write to the file\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        tool_call_id: Tool call identifier for message response (injected in tool node)\n",
    "\n",
    "    Returns:\n",
    "        Command to update agent state with new file content\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    files[file_path] = content\n",
    "    return Command(\n",
    "        update={\n",
    "            \"files\": files,\n",
    "            \"messages\": [\n",
    "                ToolMessage(f\"Updated file {file_path}\", tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557741d-20c4-434e-b565-0dfd2729f7af",
   "metadata": {},
   "source": [
    "# Revisiting state and reducer \n",
    "In the previous notebook, we defined the file state and reducer, but did not describe them. Let's do that here.\n",
    "In `DeepAgentState`, `files` is defined as a dictionary with a key and value. As was mentioned above, the key is the filename and the value is the content of the file. `files` are added to state using the `file_reducer` when the `Command` in `write_files` is executed. In this reducer, `left` is the existing files in state and `right` is new values. The final statement allows the new values to overwrite old values: `{**left, **right}`, Python unpacks `left` first, then `right`. Any duplicate keys from `right` overwrite the earlier values from `left`.\n",
    "\n",
    "```python\n",
    "def file_reducer(left, right):\n",
    "    \"\"\"Merge two file dictionaries, with right side taking precedence.\n",
    "\n",
    "    Used as a reducer function for the files field in agent state,\n",
    "    allowing incremental updates to the virtual file system.\n",
    "\n",
    "    Args:\n",
    "        left: Left side dictionary (existing files)\n",
    "        right: Right side dictionary (new/updated files)\n",
    "\n",
    "    Returns:\n",
    "        Merged dictionary with right values overriding left values\n",
    "    \"\"\"\n",
    "    if left is None:\n",
    "        return right\n",
    "    elif right is None:\n",
    "        return left\n",
    "    else:\n",
    "        return {**left, **right}\n",
    "\n",
    "\n",
    "class DeepAgentState(AgentState):\n",
    "    \"\"\"Extended agent state that includes task tracking and virtual file system.\n",
    "\n",
    "    Inherits from LangGraph's AgentState and adds:\n",
    "    - todos: List of Todo items for task planning and progress tracking\n",
    "    - files: Virtual file system stored as dict mapping filenames to content\n",
    "    \"\"\"\n",
    "\n",
    "    todos: NotRequired[list[Todo]]\n",
    "    files: Annotated[NotRequired[dict[str, str]], file_reducer]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0a899",
   "metadata": {},
   "source": [
    "We have a virtual filesystem and tools to work with it.  Let's build a simple research agent to try it out. \n",
    "The agent will store the user's request and then read it back before answering the user's question! \n",
    "\n",
    "Note that this simple approach is [very useful with long-running agent trajectories](https://www.anthropic.com/engineering/multi-agent-research-system#:~:text=Long%2Dhorizon%20conversation,across%20extended%20interactions.)! In this simple example, all information is easily kept in context, but for long-running agents, context content can be compressed or eliminated. Storing information prior to compression and retrieving it when it's needed is smart context engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a1ac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to a virtual file system to help you retain and save context.                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Workflow Process                                                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Orient**: Use ls() to see existing files before starting work                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  you directly answer the user's question.                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the user's question.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to a virtual file system to help you retain and save context.                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Workflow Process                                                                                          \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Orient**: Use ls() to see existing files before starting work                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  you directly answer the user's question.                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  the user's question.                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File usage instructions\n",
    "FILE_USAGE_INSTRUCTIONS = \"\"\"You have access to a virtual file system to help you retain and save context.                                  \n",
    "                                                                                                                \n",
    "## Workflow Process                                                                                            \n",
    "1. **Orient**: Use ls() to see existing files before starting work                                             \n",
    "2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     \n",
    "3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that you directly answer the user's question.\"\"\"\n",
    "\n",
    "# Add mock research instructions\n",
    "SIMPLE_RESEARCH_INSTRUCTIONS = \"\"\"IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer the user's question.\"\"\"\n",
    "\n",
    "# Full prompt\n",
    "INSTRUCTIONS = (\n",
    "    FILE_USAGE_INSTRUCTIONS + \"\\n\\n\" + \"=\" * 80 + \"\\n\\n\" + SIMPLE_RESEARCH_INSTRUCTIONS\n",
    ")\n",
    "show_prompt(INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94f78c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to a virtual file system to help you retain and save context.                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Workflow Process                                                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Orient**: Use ls() to see existing files before starting work                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  you directly answer the user's question.                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the user's question.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to a virtual file system to help you retain and save context.                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Workflow Process                                                                                          \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Orient**: Use ls() to see existing files before starting work                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Save**: Use write_file() to store the user's request so that we can keep it for later                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  you directly answer the user's question.                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  the user's question.                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydB2AUxf7HZ/dKyqX3hBCSEBJ6M4CiFAFRH2BA8SFNwEcRBPEvRd8DAfEpIKKiIkVAQEqUTiBSRAia0Hl0CZAQSEIKIfUu5XK3+//tbnK5JHeBYG4zezcf4Nidmd1L9r43M7/fzPxGzrIsIhAaGzkiEDCACJGABUSIBCwgQiRgAREiAQuIEAlYQIRYkwep5Zfi8wqyy8tKGECvRZQcsTpE0YiFPwxFUQx3wsM5v1gKwR8KsQxCNBxyByzF0hTFpVDgHaO4XOFauiIX/tBypNcxFOJuBel6hoWrhQLcjeGe8E94F5qlGKrqR6x8FwN2KplMhuydZf4hjpF9XZEEoYgfUSDtZtmJ3dn5OVoQBy2jHFRyhR0tkyNdGUMrKKac5bUH2mI5HfDKEnTIHdDcOSgDLoQkQSIUXVmYL0Lx11bojC9Oyym9nqVYQ2HuhpUFuFsyTMVHQ1OIMfqU+K8EQtWEKNeVseVlevjy6HSs3I4ObO4w4F9+SDoQIaKsu9qYtffLinUevnbtnnFt28MFSRoGHduec+e6ukSj9w2yH/puEyQFbF2IO5bfz7xX3KyV86Dxvsi6yEnXHVifVlyk7/26b6suTghvbFqIq/+d7OAgf3NeELJerp1S/7ErKzDcceB4f4QxtivEtXOSm4SpXh5nbRWhSdbOvdOlv0eHnvjaMTYqxFUfJIV1cOk3whvZDD/MveMTaB/1Nqb1Io1sj/XzU5q1dLIpFQIT/huSnVYav+8hwhKbE+LeVRnwaiMtcg0mLAi5GJdv7PfBBxsToh6l3dK89XEwsk3kKDDMYf2COwg/bEuImxbd8wp0QDZM1OQA8C/ePK9GmGFbQizM1Q6TiIPXcjRp7hi/Lwdhhg0Jcd+qDAdHOZIhMfnwww/37t2L6s8LL7yQnp6OLMCg8QHFaj3CDBsSYnZaWbO2KiQu169fR/UnIyMjLy8PWQaZEintqKPReFWKNiTEslJ95PMeyDLEx8dPmjTpueeeGzx48Pz583NyuI85MjLy/v37n3zySe/eveFUrVavWrVqzJgxQrGvvvqqtLRUuLxv377btm2bMGECXBIXFzdo0CBIjIqKmjFjBrIAbj52GckahBO2IsSky8U0hdx8LdIw37hxY/r06V26dNmxY8fs2bNv3ry5YMECxKsTXj/66KPjx4/DQXR09IYNG0aPHv31119D+SNHjqxZs0a4g0Kh2L17d0RExIoVK5599lkoAInQpi9btgxZAN9m9iXFeHlxbGU+YsadEpmCQpbh4sWL9vb2b731Fk3Tfn5+rVu3vn37du1io0aNgpovJCREOL106VJCQsK7776L+BmLrq6uM2fORKLgG2R37SQRYmNQomHkcksJsWPHjtDIvvfee926devZs2fTpk2hha1dDKq9kydPQsMNVaZOp4MUD4+qrgLIF4mFh5eSZfAa2rWVppllGL3FHn3Lli2/+eYbb2/vb7/9dsiQIVOmTIHarnYxyIW2GArs2bPn3Llz48aNM85VKpVINOQybvItTtiKEB1Ucpa14KPv3r079AVjYmKgd1hQUAC1o1DnGWBZdufOncOGDQMhQvMNKUVFRaiRyM8u5WaJ44StCNG3qT2jt1SNeP78eejtwQFUigMHDgRTF0QGLhjjMuXl5SUlJT4+PsKpVqs9ceIEaiSyU8tkciLExiA8UqXTMtpii2gRGmIwlnft2gXOv6tXr4J1DIr09/e3s7MD5Z06dQoaYrBjgoOD9+3bl5aWlp+fv3DhQuhZFhYWajQm3ChQEl7BrIa7IQsAppvSAa+P3ob8iHIlffpQLrIAYA5Dg/vFF1/AcMjEiRNVKhX0BeVyzhAEU/rs2bNQR0J1+Nlnn4FxPXToUHAidu3aderUqXDar18/8DXWuGFgYCC4EsHpCN1KZAHys7V+Te0RTtjQxNifl6UWF+nGLQhBNs+3/3frXx83d3TBqBqyoRrxhZG+6gIdsnlif8xQ2NFYqRDZ1AJ7Dz+lvaNs76r7UW8HmCyg1+vB4WwyC2wL8AJSpizN0NDQ9evXI8uwgcdklpOTE4wZmsxq06YNjNAgM9z9q/ipPpYa6nxibGvNStqt0r2r0t5ZFmauQO3umgB85PDBm8yCvqDBFm5winhMZoELHbqYJrPgOwPWksmsI1uyk68UTVrcHGGGzS2e2rYkVa9nR/3HmpeQ1sGKmUmvTm7m3xy7ltDm1qwM/6Cppkh35pClJlnhzIaPU5qGqzBUIbLNVXyTFoWe/S23MNu2moKtS9LkCvqViZgGxLHdBfbQSL3whn94pCOyATZ+cs8zQDkQ47BMNh1y5PuZSQHBDoOnBiCrZt28FAcn+YjZgQhjbD0I048LUsqK9d1e9u70vMSDgJli36qMe7c04Z1c+o+ylF3fUJCwdChh38PL8fnwFEJaO/Uf7kuLOBvLQiRd1EAnODdb6+yqGP1hkMjrxZ4MIsQKju94cPuSulStp2SUykWucpWrnOS0nCnXVj0fmuYDZho9MFqGGMOCOIoP4InYqliufEBO4X9EVcV4lcm4EJ3cgZzW6xjD5cKdKwqz/MVsZcBPPoN3qMMpY5TIXaVQ0DodKinUgUOgRMPAdS6eit6v+TRpgdeAch0QIdbkz70P05OKSwr18NEyDKvXVT2fSl1VQckQa7Qyk4tqjGhDGe7hVg7GGK5lGEZG00IRCspWxiSu1CEX5JiTnHAtCJE/4guwvEgZlqWpal8HpFDS8JWwc6CdPZQRnZwisI+GWBsiRLGZNm3aiBEjnnnmGUQwggRzFxudTifMECMYQ56I2BAhmoQ8EbEhQjQJeSJiU15erlAoEKE6RIhiQ2pEk5AnIjZEiCYhT0RsiBBNQp6I2IAQSR+xNkSIYkNqRJOQJyI2RIgmIU9EbIgQTUKeiNgQIZqEPBGxAYc2EWJtyBMRFW5XcYbhtpsnVIcIUVRIu2wO8lBEhQjRHOShiAqZ8WAOIkRRITWiOchDERUiRHOQhyIqRIjmIA9FVIgQzUEeiqgQY8UcRIiiQmpEc5CHIjbmYrnaOESIogKDe5mZmYhQCyJEUYF2ucbWaAQBIkRRIUI0BxGiqBAhmoMIUVSIEM1BhCgqRIjmIEIUFSJEcxAhigoRojmIEEWFCNEcRIiiAkLU6/WIUAtb3HmqcYHBFaLF2hAhig1pnU1ChCg2RIgmIX1EsSFCNAkRotgQIZqECFFsiBBNQoQoNkSIJiE7T4lEx44dabrCNIRnDsfwOnDgwIULFyICsZpFo3379ojbVpIDXIkURfn7+48aNQoReIgQReLNN99UqVTGKR06dAgPD0cEHiJEkejXr5+x7Dw9PYcPH44IlRAhisfYsWNdXFyE45YtW7Zr1w4RKiFCFI8ePXpERETAgaur68iRIxHBCGI110KPTuzL0xRqdVo9vyk9t/M8Led3qmf5Pef1TOUBCwYwLaegAMuwXArDIIbLYhiG26+eQvyu4NxDhjuwDJWXm3f12lWVyqFz50hhC3qZnGL4y+GYlkHJimPutPLOwimUNN7FvMYpoHSQ+zV16NDLGUkQIsRq/LIsPSerVKGUwcevL2d5JXEbyNMybjd7BAeVigTRMHpOa5DFyYUVxMqXqSwsyJDlnjKnKr1eT7E0KBSMZs6Hw3DNEXc5vBl/TNG8a4et2NOe064eGT4fmQwZz9rh3qX6JB6lPUiTu0HfYX5hnRyRpCAO7Sr2rr5fXMiMntMcSZmki+rforNopW9oGylpkdSIFexafr9YrY+a2hRZBZs/TR41K9RZOtFNiLFSQWZaad+Rgcha8PKzj1mXiqQDESLH1T+KZHLk5E4ha8E/1FFTKKURbdJH5IBGmSlH1oS9iirXSmlBAhEih47R6Rmr6itDzx+8QhKCCJGABUSIBCwgQuSgrM6FxdIwJiQl24sIkYeW1If2OLD86I50IELkYK3OrQ91vLS+W0SIHBRN0TQZYWpMiBA5uFkHjFU1zty3itSIhEaHE6GkqngiRB5rM1WkBxEiBw1ms3WNunNzGkmNKDkYlp9QbU2wpI8oQaTl+30cuApeUr8TmQbGw4LNjG9LtnvPL4uWzK/XJYghTbMEYXkHMMKVxMTryNohQuSg6XobK2q1evuOzWfOnkxJSfL08Orevddb4ybb29tDFsMwy79Z8mf8caVC2bfvS23bdPj3nPd2bj/k4eGp0+nWrf/+1Ok/s7Mz27btOCTqn08//Zxww8Gv9hs39u2CgvyNm9Y4ODh0iXxm6jszPT293nt/4qVLF6DA4cMHYvYed3JyQtYIaZo5uCG+eo7M7todvXXbhmH/HP3Zp19PmjT9eNwREJCQtX3Hlpj9u6ZNnbVq1WYHB0dQHuK1Dq/ffPv5jp1bhwwetnVLTK+efed/PDvuxFHhKoVC8fPPm6DYnt1HN/6488rVixs2rob0r79c06pV2/79Bxw7eu7xVchKq2EmNaIAP9Rcv6b5n6+PAiU1axYinF69eunM2YRJE9+F40OH9/fs0ad3r35wPHLEOEgXypSVlUHWiOFjXxn0Gpz+4+UouGrTTz/AfYQCTZo0HTXyLe7IyRlqxJs3/0JPCiU11ygRIg9V7ykCUIGdPXdy8ZL5t5NuCvEO3d094FWv16ekJL/80iuGkj179L18+X9wAMLSarWgMENWxw5P/XpwX0FhgauLK5yGh7cyZDk7u2g0amQzECHysKi+82/W/PBtbOweaJRBWL6+fmvXrYj9dS+kqzVquJWjY1XgL1dXN+FArS6C12nT/1XjVnm5DwUhWp8X6fEhQuSgOQnUQwQgtZj9O4e+NmLggCFCiiAywNGBW9ZeXl61Fisv76Fw4OnFLTOe8f4caIKN7+bj44caGslNayNC5ODjfNTjo4P2t6SkxMvLRziFBjfh5AnhGJpsHx9fMKUNheMT4oSDwCZBdnZ2cNCpY6SQkpeXy1efFgjJIDUrlFjNHJwG2XrUiHK5PCgoGLp36ffTwOHy+RcL27XtWFRUqNFoILf7Mz0PHzlw9twpEBlY0JAuXAWCGztmElgnV65cBO2CvTxz9pSvly9+5NtBDfrXX1cv/O+scUVbN5Jb/ECEyEFR9e6efTTnM3s7+7Hjho56c/BTnbuOHz8VToe81i8j8/6YNye2a9dp9gdTR7855O7dO9CCI067Cnh9Y9ibs2bO2xq9YVBUb/A1BvgHzpgx95HvNWjAq/DzzZr9TnGxBlkpJPYNx8nYnAu/Fbw5v2HCL5WWloK/GqpM4TT6501btqyP2XcciciN0wWnDz6Y+mUYkgikRqyk4QxWUN7Et0fu3BUNrfbvxw7/sn3zK68MRYQ6IcYKBzfQ3HANw9gxEwsK8g4f3v/D2m+9vX1hHAXc2khcqqIsSgQiRA4KNfCkqenvfoAaFehTSqvLRYTIwyCG9JUbFSJEDkpGyWiybqUxIULkYDgQoREhQuSguRX21hWWDkkMIkQOfvGUVTXNNfCzegAAEABJREFUnH+eLJ6SHNwEbSvzqLJkzYoEkVx81UdC/IiShPvYrCtGIvEjShIuPKKVhXqQGkSIHEz9F08RGhYiRA6lUq6wty6HNo0UChmSDqQ94ghs7shIaXecR5OfUS6trxYRIodfqFKppM/+moushbQkdUColDaFJEKs4KUxAYkX8pBVcHB9BnR5Xxrjg6QDmaFdQUlJyfvT57RzfcfTzz64pYuditVV9yxyO4gbPyrWEJaVqhGLsGZJIZEvW8O5VyPRcJ9q6ZVr/6nKQxgDMumbkdOyhxna1MRCpaNsxGyJbXBJhFjBTz/91KZNm85tO0cvTy3K1Wl1DGO0P7wwYdHwqIwUw9aI3kTxIeEM7nFjbdUWq2EepHDnisSKN6oWfKJ23E2D3A1ZCjtKoZCXy7LavVDeokULHx9SI0qH3Nzc5cuXf/zxx0gspk+fPmzYsO7duyMLsG7dujVruBhOzs7OLi4uQUFBHTp0CA8P79y5M8IbW3ffzJ07F5SBRMTLy0ulUiHLMHLkyAMHDty7d0+tVqenp9+4cePIkSNubm7wjnv37kUYY6M1YmZm5unTp6OiopDVsWrVqrVr19ZIhE/5/PnzCGNs0WouKCgYP378008/jRoD+A6UlZUhizF06NAmTZoYp9jZ2WGuQmRrQszIyIAGS6fT7d+/39fXFzUGH3zwwe3bt5HFgKb/ueeeMzR0cLBo0SKEPTYkxEuXLk2cOBE+J09PT9R4wBfAIsFujBg+fLi3NxfwSWiR9+zZs3LlSoQ3NiHErKwsxMfJjImJEcIgNSKff/55SEgIsiSBgYGRkZEMw/j5cXHGvvzySxg4mjZtGsIY6zdWwFr8/fffwUeD8AD6BlApyuUW91f079//8OHDhtOTJ0/OmTNn06ZNIFOEH9ZcIxYWcmG4iouL8VEhMHny5OzsbGR5jFUIPPPMM9BGT5069dChQwg/rFaI69evj42NRXyHCeEENJfgcEaNAbi4QYsnTpz46quvEGZYYdNcXl7+4MEDeOJTpkxBBFNs3boVuiu13Y2NiLUJER4u9I2g1oHuOcISGPaAXhrd2KsGwYfw9ttvb9y4EQYAEQZYVdO8Y8cO8BHCACu2KgRGjRpVWlqKGhsYg4Y2esGCBdB0IAywEiFu374dXvv06QPfcoQ3AQEBmHxPFAoFtNFXr1799NNPUWNjDUKcMWOG0MHw8PBA2BMdHS2C7+bxmTt3buvWrUeOHCnsFtNYSLuPeO7cOfDcgmeuxugqzty9e7dZs2YIMxITE8eMGbN69WposlFjINUaUavVwui+0OWXkAqhdwh1D8KPiIiIU6dOffPNN9u2bUONgSSFmJubm5OTs2zZMvzne9YA2p/Q0FCEK+vWrbt//z401kh0JNY0g/4mTJgAzmp3d3dEsAwHDx5cs2YNeHacnZ2RWEhMiLt27erSpUvTpk2RNNHr9RkZGXiO9hoDzk7oMi5evLhbt25IFKTRNCcnJ7/zzjtw8Oqrr0pXhQAM+eDvYALAF3vs2LFNmzZB44NEQRpChPGSefPmIelDURSGJrM5VqxYUVZWBt4xZHmwbpqvXbt2+fJl3GYt2BpxcXGLFi2C2tGi61PxrRHBNF66dOnAgQORFQFeJzBLkaTo1avX5s2bx44de+XKFWQx8BUiDD9s2LBBTMNNBEpKSubPny+5QQQvL6/Y2FjwMgpz3S0BpkLcsmXLmTNnkNXh6ur6/fffx8TESHE7jYsXL1puxRmmC+yzs7PrvXGtRFAoFK+88kpqaioMC0loTOjWrVthYRbc6xRTIYKBgtXMgAYHnFBRUVFbt261XNSHhgWE2KJFC2QxMG2a/fz8oF+CrJq9e/cmJiaq1WokBZKSkixaI2IqxN27d+/btw9ZOzBWnp6enpCQgLDH0k0zpkKEMWUYCkM2QERERHR0NP714u3bty0qREwd2jAUBnZlY0UFER9wLsLvi+0YdEFBAQyuHj16FFkMTGtEb29v21Eh4tcP5OXlNdZcwEdi6eoQYSvEQ4cO/fzzz8iWaNeuHdSL4PFG+GG7Qnz48KHkhsL+PsLimwsXLiDMsLTvBmErxBdffPGNN95Atoejo6O9vf1nn32GcAJqREsLEVOnceNGjmtcWrdufePGDYQTtts0x8XFbdy4EdkqYKLCKyaeVBiNBNvR0uH8MBUi+Avu3buHbBswX2bOnIkaGxE6iAjbprlnz56SW6HX4ISEhIwdOxY1NiK0ywjbGtHNzQ3/FUYi0LZtW3ht3ChyNi3EM2fO4B/2WTSgXmzEJVfiNM2YChHGXu/cuYMIPO7u7kuXLoUDQ3ial156adCgQcjylJWVZWdni7ByElMhRkZGCutHCQLCkgnweGs0moEDB+bk5MCQoAhBiEXwIApgKkQXFxcJLbsUjeXLl7/88suZmZmIX/5i0VkIApae/WUAUyFeu3Zt2bJliFCdYcOGFRcXC8cURSUmJgqitBziWCoIWyHC47bo9kxSZMSIEUlJScYpWVlZ4PlHlkQcSwVhK0QY5po1axYiGCFMWJTJZIYUrVZ75MgRZEksvULAAKYObZVKhXP4tkYhOjr6woULZ8+ePX36NHgVMjIyfFWd2UKPI7tu+gf4CZuHUzRimerbjPPHdW1CTlXuUc6ganugU0hdVBTs2SP1OpWKCqsKo5p7mLMUotnKtOo3p2nKJ9DOq8mjQzXjNUN7/Pjx8IjhR4KmubCwENwWUA3A8W+//YYIRvy4MLm4QA+y03P+nIqd7xH3wSNuwTTFcuoQZCPkcZ9zhcpqKRMyKP6/iqv4/yoW8xoSq5VECBnfgeLSTepIroB0SqGk2j/r3u0fbsg8eNWI0CJv3rzZsPUDuCoQP1sbEYxY82GydzOHoZP9Eb57J1TjWkLBlfhc/2C7oNZmdzrCq484atSo2iN7Xbt2RYRK1vwnuVUXz34jJKNCoE1312GzQmI3Zpw7XGCuDF5C9PHxGTBggHGKp6cnnkGnG4VfN2bLFbKO/VyRBGnVze1i3ENzudhZzcOHDzeuFDt27IjJ1kg4kHWv1MvfHkmTzn09ystZrZl1s9gJEcZUYBRViDfi4eExevRoRKikvEwnt5fw1jhgSOVkmV4dhuNvZagU2/IgQiU6LavTliPJwuhZxsyuQn/LataWoPj9Dx6kagvztOC+Ar3DOxlyaZplGCPvFcX7BShIrSxD834GI7Mf/BGIT+kdvEgfqJfL5Cs/SOb8D2y1yGCct4z7teCAqrob3E8GP4CJnxOqV4qm5TKk8pA3ae7QfaDtLojBlicU4sGNWfduaLRljExGy5VySi5T2ssZhmWNvJk0RTNstSiAgm/KoDyqpmdUcIix/DhqRTHeE1bL2cm7s3j3WDUd0xTFmHJnyeUykKu+TJebqcu6m3f+aK6jkzz8KZceg4kicaHeQjywPivlulomp529nMPbSGDvu9rotfq0a7mX48G5ld/5eben/yEZOUKVb61hI+snxNX/vgN1XLP2fk7eUrXdAJlS1qwT5yTPTi48f/Th1ZNF4z8JRlIAOh6S3juRa8do01+kxzVWUm+WfPt/t529VC17B0lahcb4hLq06RdCy2Tfz0xCBMvD9boY01+kxxJiwYPyvavSW/cNCWhthZ2q0G4BfuE+K4gWG5VHC/H2peItn6e2fSHEaP6RteHR1DG0S5AEtEgh6+whPo4QD228H9bV+ld2OrjQXs3cVn+YjHCGRRLuIdbJI4S4+j93nH2clE7WWxka4RvmRsnpLUtSEa5QlLTrRME1ZzKrLiHG7cxhdGxQBxuahRX+bNO8zLLMFExHL9iarn2JQdPI3M9flxCvJuR7h9jctsgqD4eYtWkIU6p78KUGNwZRX6s5fh83Y8cr2AVhycUrv838qJtak4campBIv1KNrvAhjjtDwdim+P7swa/22/TTWmRhzArxxtkilbsDskmU9oojW3Dc00AY/6zXJR8v/DD2170Ie8wKsUSj8w2z0aFYJx+nh5lahCFsvdcYJSZeR1LA9BDfjTNqaAIcXBXIMqTcu3z42NrUtOtOKvdWEc/1f368vT23E1j8qe1H4tZPfmvlpuh/Z2Un+/uG9ew+vEvnip1y9x/89tylWDulY6f2L/p4BSGL4R/qej01H0mf5/tGwuvSLz5ZueqrmL3H4Tg+Pm7jpjV3791xdXULC4uYPu0DX18/oXAdWQLwHdi5a9uhQ/tT0+42CwqJjHz6rXGTZfVxL3P9inpZzXeuq7lZU5Yh52Hq6g3TysvLpk5cO2bEkoysWyvXT9bzy9FkckVJSdGeA1/8c/B/li481b5tn1/2/DcvnwtmkHBmZ8KZHa8OmDV90o+e7gFHjq1DFoNW0rSMunleg3CD4ma+PX7xg7Hx8Dpr5keCCs+dPz1vwaz+/Qf8Eh07/6PFWVkZX3+zWChZR5aBXbuiN29ZP/S1EdFb9w8a9NqB2D3RP29C9YGrzdn6GCvqXL1cYak5sxcuHZTLFGOHL/H1DvbzCX09ak56RuLVvyoiFuj15S88P75Z03YURUV2HADfwvSMm5D+58lf2rfpC9J0dHSBOjIsNBJZElpGZ6eWIczgahPmya3m9T+u7NmjDygJ6rw2bdpPmfz+qVN/3uDb7jqyDFy6fCEiovWLLw50c3MfOGDIiu82dOv6LGogTKutXM+wFnOcQrvcNLC1SlWxytXD3d/TI/DO3YuGAkFN2ggHjg6czV5SWgRyzMlN9fUJMZQJDGiJLAm3tlqDXTeRZf7WyEpy8q2WLdsYTiPCW8PrjRvX6s4y0LZth/PnT3++dOHBQzEFhQVNAgLDwhpsOZHpPiL1d753j6KkVJ2afh2cL8aJhUVV67tqT7krLdMwjN7OztGQolRa1qKnuO8ofusoKlfNPwFqtbqsrMzOrmrmlKMj9zyLizV1ZBnfAepLR0dVfELcks8/lsvlvXu/MGnCu15eDTPeYVqICqWcQjpkGZydPUOadXyxz0TjRJWqriWS9nYq6LWVl5caUsq0xciSQE/GXoVfPBa24t8TYG/P6ay0tGrtkobXmaeHVx1ZxnegaRpaZPibkpJ84cKZDZvWaDTqz/5bj7DK3Ix6M31c08/a1VORk2GphinAt8X5S7GhwZ0MER0ys5O9PeuygqGOdHfzT7l3pVdln+SvxHhkSRiG9QvBb9olxT6xRxvqsIjwVteuXTakCMehzVvUkWV8B7CXw8NbhYQ0Dw4Ohb9F6qIDsbtRfaj3yErz9k6MzlJDC+CRYRhm369fabWl2Q/u7j/03bLvRmRkPSIIXYe2/a5cPwYDKnD8+x+b7qZdRRZDq9YjBoV1cESYQdVzoYCdnZ23t8+5c6f+d/GcTqcbMnjYn/HHd+7cVlhUCCnfr/yyc6cuLcIioGQdWQaO/n4QLOuEhBPQQQRT5o8/f2/bpgNqIEzXiKHtHUG8hTllLl4Nv80LmL0zp2499sdPX68ak/0gJSiwzeuD56IHC7gAAAR0SURBVDzS+OjXa5xGk7cndtnmX+ZAy/7Ky+9t3T7PQvPms+/kKexwXGjLrZOs5288csRbP25YdeZswrat+8E78yAn++ftP333/TLwEUY+9fSE8VOFYnVkGZjx/tzvVnwx56P3Ebfk3BPa6NeHjkINhFlP/cZP7upZWWgXf2R7JMal+gXbR73thzBj5eykJmEOzw8LQNJkw4LbQ95uEhhhwtA0+73v0MOtpBA7R5o4lGt1UZOwU6EVwBkrZvoWZg3Djr1dTx7IybiR69/S9JrR/IKsL74bYTLLwc6ppMx0jBM/79CpE39ADcfcT/uay4LRGpnMxC8YHNR+/Giztl7S6QwXNyW+00+lvJyUM1bMdC3q8lB0fdn79K8PzAnR2cnz/Sk/mcwCK0SpNG1y0nQD+0TM/Qzcj1FeplSY6OPKZXVFdCspLB23WIxgvU8AZS4gpvSpSxZP9XG58md+yrnM4EgT7RRUNh7ujd9Zadif4eafqU1bONK4hh7kImlIeoq2eR5hG46dFwQ1RH6GZb3HmJB+JQc8m1GT8TYFKCnP0Dbfs3i0k2Ly4uZp17KRtZPxV17hQw3mIR+EUNdIstCcsfLEkR5kaPLnza8euZObXoKslLTLOYXZhZOX4L6PAVcZSrll5vq3fyfSg0yGpn4ZlpmYBf1FZHUk/pGqyddMWiyV3TSs01ipx/jBlKXNEau7/ntKZmLDL1lqFO5efAA1vaubfNIiaaiQa9Zo6zRW6udMGTuv2elDeReP5+XeL3RwtvNu7uHkLp3g9pXkpasfphSUFmsdnORDJjVtEtHww5gWoo6mTRLwSwVMZ9Xbq9ftRXf4e+63/GsJBSnn0xE3vx88OTS39FtGGQfmNN5kptYpy8fYrDo1TLUz7EVDcZMiWVoINCvcAQk2I99lrwzjyZ1Xxo2l+Peg+dmUFa/8fkq0DN5JrtPq9Do9lIRizh6Kfm80CW4ruWWKrKTjI/JLBUxnPaF7ObKfG/yFg9v/Uydd1hTl69QF5dy0ZiMhQs9Sr2cNQV3Bk83oqoLFUiDdyjDDfGhZuiK9YtEkH5+YVxUf3oDiN+hi+eknQthiFjGUsOMX6IwLFAunMobVU5ScRXpuVy44FoIZyxWU0gGOFe4+jq26ujQJk25YPUrKFWJd/N1xjrBOTvAXEcSCslJjBdNNIQkmUShlcoWEA2LJ5RQXftlkFiJIB4U9VVaMYyyUx4RFVGCoaetWwrvH2CDBrZwfZkp1bl7Cvhw7BxkyU6ETIUqJXq95gDH3+1ZJjrjevVbY53Ufc7l47ddMeBw2/fceRdOdens1ayMB81+dz1747cHdG0Vj5garXM12cIkQJcn2r9NzM7V6HaM32uqLrdzYu14YNh1/LOoZjYyWcSFSYOCg/0jfgDq9ZkSIUkaLSkqq9nyrcHZX35GL5b38FSWMBxAMCE5/4028KKMRhqpEI8WyRimGXOGaGnKSyRwez7lHhEjAAuK+IWABESIBC4gQCVhAhEjAAiJEAhYQIRKw4P8BAAD//yZb3M4AAAAGSURBVAMAfz3rSoIOL84AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import format_messages\n",
    "\n",
    "from deep_agents_from_scratch.file_tools import ls, read_file, write_file\n",
    "from deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "# Mock search result\n",
    "search_result = \"\"\"The Model Context Protocol (MCP) is an open standard protocol developed \n",
    "by Anthropic to enable seamless integration between AI models and external systems like \n",
    "tools, databases, and other services. It acts as a standardized communication layer, \n",
    "allowing AI models to access and utilize data from various sources in a consistent and \n",
    "efficient manner. Essentially, MCP simplifies the process of connecting AI assistants \n",
    "to external services by providing a unified language for data exchange. \"\"\"\n",
    "\n",
    "\n",
    "# Mock search tool\n",
    "@tool(parse_docstring=True)\n",
    "def web_search(\n",
    "    query: str,\n",
    "):\n",
    "    \"\"\"Search the web for information on a specific topic.\n",
    "\n",
    "    This tool performs web searches and returns relevant results\n",
    "    for the given query. Use this when you need to gather information from\n",
    "    the internet about any topic.\n",
    "\n",
    "    Args:\n",
    "        query: The search query string. Be specific and clear about what\n",
    "               information you're looking for.\n",
    "\n",
    "    Returns:\n",
    "        Search results from search engine.\n",
    "\n",
    "    Example:\n",
    "        web_search(\"machine learning applications in healthcare\")\n",
    "    \"\"\"\n",
    "    return search_result\n",
    "\n",
    "\n",
    "# Create agent using create_react_agent directly\n",
    "model = init_chat_model(model=\"ollama:gpt-oss:20b\", temperature=0.0)\n",
    "# model = ChatMistralAI(model_name=\"mistral-small-latest\", temperature=0.0)\n",
    "tools = [ls, read_file, write_file, web_search]\n",
    "show_prompt(INSTRUCTIONS)\n",
    "# Create agent with system prompt\n",
    "agent = create_react_agent(\n",
    "    model, tools, prompt=INSTRUCTIONS, state_schema=DeepAgentState\n",
    ")\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054ebcc",
   "metadata": {},
   "source": [
    "Start the graph with no `files` in state and an user research request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e90ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── 🧑 Human ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Give me an overview of Model Context Protocol (MCP).                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m 🧑 Human \u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Give me an overview of Model Context Protocol (MCP).                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: web_search                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"query\": \"Model Context Protocol MCP overview\"                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: fcabd170-e501-4c8a-92e3-0ac0400210f3                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: web_search                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"query\": \"Model Context Protocol MCP overview\"                                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: fcabd170-e501-4c8a-92e3-0ac0400210f3                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The Model Context Protocol (MCP) is an open standard protocol developed                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> by Anthropic to enable seamless integration between AI models and external systems like                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools, databases, and other services. It acts as a standardized communication layer,                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> allowing AI models to access and utilize data from various sources in a consistent and                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> to external services by providing a unified language for data exchange.                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m The Model Context Protocol (MCP) is an open standard protocol developed                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m by Anthropic to enable seamless integration between AI models and external systems like                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools, databases, and other services. It acts as a standardized communication layer,                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m allowing AI models to access and utilize data from various sources in a consistent and                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m to external services by providing a unified language for data exchange.                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Model Context Protocol (MCP)**                                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> MCP is an open‑standard protocol created by Anthropic to streamline how AI models interact with external        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> systems—such as tools, databases, APIs, and other services. It defines a unified, language‑agnostic interface   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> that lets models request, receive, and manipulate data from these external sources in a consistent way. By      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> abstracting the details of each service, MCP simplifies integration, improves interoperability, and enables     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> developers to build more powerful, context‑aware AI assistants without having to write custom connectors for    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> every new tool.                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Model Context Protocol (MCP)**                                                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m MCP is an open‑standard protocol created by Anthropic to streamline how AI models interact with external        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m systems—such as tools, databases, APIs, and other services. It defines a unified, language‑agnostic interface   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m that lets models request, receive, and manipulate data from these external sources in a consistent way. By      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m abstracting the details of each service, MCP simplifies integration, improves interoperability, and enables     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m developers to build more powerful, context‑aware AI assistants without having to write custom connectors for    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m every new tool.                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give me an overview of Model Context Protocol (MCP).\",\n",
    "            }\n",
    "        ],\n",
    "        \"files\": {},\n",
    "    }\n",
    ")\n",
    "format_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addd08d",
   "metadata": {},
   "source": [
    "We can see the file saved in our mock file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449c8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"files\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb506b",
   "metadata": {},
   "source": [
    "Trace: \n",
    "https://smith.langchain.com/public/b03e20b4-e908-488d-84a9-8f891d17addd/r\n",
    "<!-- https://smith.langchain.com/public/1066102f-d7b3-423c-b556-006865a1d479/r -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-agents-from-scratch-ollama (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
